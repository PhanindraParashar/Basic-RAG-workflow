{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91a1a639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Dict, Any, List, Optional, Union, TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.document_loaders.pdf import PyPDFDirectoryLoader \n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter \n",
    "from langchain.embeddings import OpenAIEmbeddings \n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.schema import Document \n",
    "#from langchain.vectorstores import Chroma\n",
    "from langchain_chroma import Chroma\n",
    "import datetime, json, time, os\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fe94110",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = \"chroma_db\"\n",
    "pdf_directory = \"Data\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f53876",
   "metadata": {},
   "source": [
    "# Load Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44008120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file llama-3.pdf\n",
      "Processing file deepseek-v3.pdf\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "for filename in os.listdir(pdf_directory):\n",
    "    print(f\"Processing file {filename}\")\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        loader = PyPDFLoader(os.path.join(pdf_directory, filename))\n",
    "        documents.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8276578f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total document Pages: 145  pages\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total document Pages: {len(documents)}  pages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b0971b",
   "metadata": {},
   "source": [
    "# Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae955f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58b90f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(texts)\n",
    "\n",
    "if os.path.exists(persist_directory):\n",
    "    print(\"ChromaDB already exists. Skipping build.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f68a497",
   "metadata": {},
   "source": [
    "# Build Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41d958f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB built successfully.\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "Chroma.from_documents(texts, embeddings, persist_directory=persist_directory)\n",
    "print(\"ChromaDB built successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29c3a713",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80acecd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n",
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "152b19c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever,return_source_documents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e8b0ea",
   "metadata": {},
   "source": [
    "# Halucination without RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1ea538a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DeepSeek V3 has approximately 1.2 billion parameters.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"how many parameters in deep-seek v3?\").content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d21e029",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c779aca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'how many parameters in deep-seek v3?',\n",
       " 'result': 'DeepSeek-V3 comprises 671 billion (671B) total parameters.',\n",
       " 'source_documents': [Document(id='89061abd-f233-4845-845a-19679fa4bc0d', metadata={'total_pages': 53, 'creator': 'LaTeX with hyperref', 'page': 34, 'creationdate': '2025-02-19T02:11:22+00:00', 'subject': '', 'producer': 'pdfTeX-1.40.25', 'source': 'Data/deepseek-v3.pdf', 'author': '', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'title': '', 'keywords': '', 'page_label': '35', 'trapped': '/False', 'moddate': '2025-02-19T02:11:22+00:00'}, page_content='DeepSeek-V3 has some limitations, especially on the deployment. Firstly, to ensure efficient\\ninference, the recommended deployment unit for DeepSeek-V3 is relatively large, which might\\npose a burden for small-sized teams. Secondly, although our deployment strategy for DeepSeek-\\nV3 has achieved an end-to-end generation speed of more than two times that of DeepSeek-V2,\\nthere still remains potential for further enhancement. Fortunately, these limitations are expected\\nto be naturally addressed with the development of more advanced hardware.\\nDeepSeek consistently adheres to the route of open-source models with longtermism, aiming\\nto steadily approach the ultimate goal of AGI (Artificial General Intelligence). In the future, we\\nplan to strategically invest in research across the following directions.\\n• We will consistently study and refine our model architectures, aiming to further improve\\nboth the training and inference efficiency, striving to approach efficient support for infinite\\ncontext length. Additionally, we will try to break through the architectural limitations of\\nTransformer, thereby pushing the boundaries of its modeling capabilities.\\n35'),\n",
       "  Document(id='d234459c-9045-46d2-ae20-ae0f65e0c3af', metadata={'author': '', 'trapped': '/False', 'keywords': '', 'page': 23, 'creator': 'LaTeX with hyperref', 'total_pages': 53, 'source': 'Data/deepseek-v3.pdf', 'moddate': '2025-02-19T02:11:22+00:00', 'title': '', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creationdate': '2025-02-19T02:11:22+00:00', 'page_label': '24', 'subject': '', 'producer': 'pdfTeX-1.40.25'}, page_content='In Table 3, we compare the base model of DeepSeek-V3 with the state-of-the-art open-source base\\nmodels, including DeepSeek-V2-Base (DeepSeek-AI, 2024c) (our previous release), Qwen2.5 72B\\nBase (Qwen, 2024b), and LLaMA-3.1 405B Base (AI@Meta, 2024b). We evaluate all these models\\nwith our internal evaluation framework, and ensure that they share the same evaluation setting.\\nNote that due to the changes in our evaluation framework over the past months, the performance\\n24'),\n",
       "  Document(id='c88678b4-fa8e-4b88-b20d-7f4cd35b874c', metadata={'author': '', 'page_label': '6', 'total_pages': 53, 'subject': '', 'producer': 'pdfTeX-1.40.25', 'page': 5, 'creationdate': '2025-02-19T02:11:22+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'title': '', 'source': 'Data/deepseek-v3.pdf', 'trapped': '/False', 'moddate': '2025-02-19T02:11:22+00:00'}, page_content='DeepSeek-V3 emerges as the top-performing model for coding competition benchmarks,\\nsuch as LiveCodeBench, solidifying its position as the leading model in this domain. For\\nengineering-related tasks, while DeepSeek-V3 performs slightly below Claude-Sonnet-3.5,\\nit still outpaces all other models by a significant margin, demonstrating its competitiveness\\nacross diverse technical benchmarks.\\nIn the remainder of this paper, we first present a detailed exposition of our DeepSeek-V3\\nmodel architecture (Section 2). Subsequently, we introduce our infrastructures, encompassing\\nour compute clusters, the training framework, the support for FP8 training, the inference\\ndeployment strategy, and our suggestions on future hardware design. Next, we describe our\\npre-training process, including the construction of training data, hyper-parameter settings, long-\\ncontext extension techniques, the associated evaluations, as well as some discussions (Section 4).\\nThereafter, we discuss our efforts on post-training, which include Supervised Fine-Tuning (SFT),\\nReinforcement Learning (RL), the corresponding evaluations, and discussions (Section 5). Lastly,\\nwe conclude this work, discuss existing limitations of DeepSeek-V3, and propose potential\\ndirections for future research (Section 6).\\n2. Architecture\\nWe first introduce the basic architecture of DeepSeek-V3, featured by Multi-head Latent Atten-\\ntion (MLA) (DeepSeek-AI, 2024c) for efficient inference and DeepSeekMoE (Dai et al., 2024)'),\n",
       "  Document(id='ecce1504-9bea-42cc-a0c4-12561e0d7bd1', metadata={'keywords': '', 'creationdate': '2025-02-19T02:11:22+00:00', 'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'author': '', 'title': '', 'page': 21, 'page_label': '22', 'moddate': '2025-02-19T02:11:22+00:00', 'subject': '', 'total_pages': 53, 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'Data/deepseek-v3.pdf'}, page_content='is 2048. Among the routed experts, 8 experts will be activated for each token, and each token\\nwill be ensured to be sent to at most 4 nodes. The multi-token prediction depth 𝐷is set to 1, i.e.,\\nbesides the exact next token, each token will predict one additional token. As DeepSeek-V2,\\nDeepSeek-V3 also employs additional RMSNorm layers after the compressed latent vectors,\\nand multiplies additional scaling factors at the width bottlenecks. Under this configuration,\\nDeepSeek-V3 comprises 671B total parameters, of which 37B are activated for each token.\\nTraining Hyper-Parameters. We employ the AdamW optimizer (Loshchilov and Hutter, 2017)\\nwith hyper-parameters set to 𝛽1 = 0.9, 𝛽2 = 0.95, and weight_decay = 0.1. We set the maximum\\nsequence length to 4K during pre-training, and pre-train DeepSeek-V3 on 14.8T tokens. As for\\nthe learning rate scheduling, we first linearly increase it from 0 to 2.2 ×10−4 during the first\\n2K steps. Then, we keep a constant learning rate of 2.2 ×10−4 until the model consumes 10T\\ntraining tokens. Subsequently, we gradually decay the learning rate to 2.2 ×10−5 in 4.3T tokens,\\nfollowing a cosine decay curve. During the training of the final 500B tokens, we keep a constant\\nlearning rate of 2.2 ×10−5 in the first 333B tokens, and switch to another constant learning rate\\n22')]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.invoke(\"how many parameters in deep-seek v3?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea6c2b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='89061abd-f233-4845-845a-19679fa4bc0d', metadata={'source': 'Data/deepseek-v3.pdf', 'author': '', 'creator': 'LaTeX with hyperref', 'keywords': '', 'total_pages': 53, 'creationdate': '2025-02-19T02:11:22+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'moddate': '2025-02-19T02:11:22+00:00', 'page': 34, 'trapped': '/False', 'producer': 'pdfTeX-1.40.25', 'title': '', 'page_label': '35'}, page_content='DeepSeek-V3 has some limitations, especially on the deployment. Firstly, to ensure efficient\\ninference, the recommended deployment unit for DeepSeek-V3 is relatively large, which might\\npose a burden for small-sized teams. Secondly, although our deployment strategy for DeepSeek-\\nV3 has achieved an end-to-end generation speed of more than two times that of DeepSeek-V2,\\nthere still remains potential for further enhancement. Fortunately, these limitations are expected\\nto be naturally addressed with the development of more advanced hardware.\\nDeepSeek consistently adheres to the route of open-source models with longtermism, aiming\\nto steadily approach the ultimate goal of AGI (Artificial General Intelligence). In the future, we\\nplan to strategically invest in research across the following directions.\\n• We will consistently study and refine our model architectures, aiming to further improve\\nboth the training and inference efficiency, striving to approach efficient support for infinite\\ncontext length. Additionally, we will try to break through the architectural limitations of\\nTransformer, thereby pushing the boundaries of its modeling capabilities.\\n35'),\n",
       " Document(id='d234459c-9045-46d2-ae20-ae0f65e0c3af', metadata={'source': 'Data/deepseek-v3.pdf', 'page': 23, 'title': '', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'trapped': '/False', 'subject': '', 'page_label': '24', 'keywords': '', 'creator': 'LaTeX with hyperref', 'author': '', 'total_pages': 53, 'creationdate': '2025-02-19T02:11:22+00:00', 'moddate': '2025-02-19T02:11:22+00:00'}, page_content='In Table 3, we compare the base model of DeepSeek-V3 with the state-of-the-art open-source base\\nmodels, including DeepSeek-V2-Base (DeepSeek-AI, 2024c) (our previous release), Qwen2.5 72B\\nBase (Qwen, 2024b), and LLaMA-3.1 405B Base (AI@Meta, 2024b). We evaluate all these models\\nwith our internal evaluation framework, and ensure that they share the same evaluation setting.\\nNote that due to the changes in our evaluation framework over the past months, the performance\\n24'),\n",
       " Document(id='c88678b4-fa8e-4b88-b20d-7f4cd35b874c', metadata={'title': '', 'trapped': '/False', 'source': 'Data/deepseek-v3.pdf', 'creator': 'LaTeX with hyperref', 'total_pages': 53, 'page_label': '6', 'moddate': '2025-02-19T02:11:22+00:00', 'producer': 'pdfTeX-1.40.25', 'subject': '', 'keywords': '', 'author': '', 'creationdate': '2025-02-19T02:11:22+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'page': 5}, page_content='DeepSeek-V3 emerges as the top-performing model for coding competition benchmarks,\\nsuch as LiveCodeBench, solidifying its position as the leading model in this domain. For\\nengineering-related tasks, while DeepSeek-V3 performs slightly below Claude-Sonnet-3.5,\\nit still outpaces all other models by a significant margin, demonstrating its competitiveness\\nacross diverse technical benchmarks.\\nIn the remainder of this paper, we first present a detailed exposition of our DeepSeek-V3\\nmodel architecture (Section 2). Subsequently, we introduce our infrastructures, encompassing\\nour compute clusters, the training framework, the support for FP8 training, the inference\\ndeployment strategy, and our suggestions on future hardware design. Next, we describe our\\npre-training process, including the construction of training data, hyper-parameter settings, long-\\ncontext extension techniques, the associated evaluations, as well as some discussions (Section 4).\\nThereafter, we discuss our efforts on post-training, which include Supervised Fine-Tuning (SFT),\\nReinforcement Learning (RL), the corresponding evaluations, and discussions (Section 5). Lastly,\\nwe conclude this work, discuss existing limitations of DeepSeek-V3, and propose potential\\ndirections for future research (Section 6).\\n2. Architecture\\nWe first introduce the basic architecture of DeepSeek-V3, featured by Multi-head Latent Atten-\\ntion (MLA) (DeepSeek-AI, 2024c) for efficient inference and DeepSeekMoE (Dai et al., 2024)'),\n",
       " Document(id='ecce1504-9bea-42cc-a0c4-12561e0d7bd1', metadata={'creator': 'LaTeX with hyperref', 'keywords': '', 'total_pages': 53, 'page_label': '22', 'page': 21, 'trapped': '/False', 'producer': 'pdfTeX-1.40.25', 'subject': '', 'creationdate': '2025-02-19T02:11:22+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'moddate': '2025-02-19T02:11:22+00:00', 'title': '', 'author': '', 'source': 'Data/deepseek-v3.pdf'}, page_content='is 2048. Among the routed experts, 8 experts will be activated for each token, and each token\\nwill be ensured to be sent to at most 4 nodes. The multi-token prediction depth 𝐷is set to 1, i.e.,\\nbesides the exact next token, each token will predict one additional token. As DeepSeek-V2,\\nDeepSeek-V3 also employs additional RMSNorm layers after the compressed latent vectors,\\nand multiplies additional scaling factors at the width bottlenecks. Under this configuration,\\nDeepSeek-V3 comprises 671B total parameters, of which 37B are activated for each token.\\nTraining Hyper-Parameters. We employ the AdamW optimizer (Loshchilov and Hutter, 2017)\\nwith hyper-parameters set to 𝛽1 = 0.9, 𝛽2 = 0.95, and weight_decay = 0.1. We set the maximum\\nsequence length to 4K during pre-training, and pre-train DeepSeek-V3 on 14.8T tokens. As for\\nthe learning rate scheduling, we first linearly increase it from 0 to 2.2 ×10−4 during the first\\n2K steps. Then, we keep a constant learning rate of 2.2 ×10−4 until the model consumes 10T\\ntraining tokens. Subsequently, we gradually decay the learning rate to 2.2 ×10−5 in 4.3T tokens,\\nfollowing a cosine decay curve. During the training of the final 500B tokens, we keep a constant\\nlearning rate of 2.2 ×10−5 in the first 333B tokens, and switch to another constant learning rate\\n22'),\n",
       " Document(id='835fd861-8b65-4023-92f2-215db7eb66c7', metadata={'author': '', 'keywords': '', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'moddate': '2025-02-19T02:11:22+00:00', 'page': 30, 'creationdate': '2025-02-19T02:11:22+00:00', 'producer': 'pdfTeX-1.40.25', 'trapped': '/False', 'source': 'Data/deepseek-v3.pdf', 'creator': 'LaTeX with hyperref', 'page_label': '31', 'title': '', 'total_pages': 53, 'subject': ''}, page_content='are evaluated in a configuration that limits the output length to 8K. Benchmarks containing\\nfewer than 1000 samples are tested multiple times using varying temperature settings to derive\\nrobust final results. DeepSeek-V3 stands as the best-performing open-source model, and also\\nexhibits competitive performance against frontier closed-source models.\\n5.3.2. Standard Evaluation\\nTable 6 presents the evaluation results, showcasing that DeepSeek-V3 stands as the best-\\nperforming open-source model. Additionally, it is competitive against frontier closed-source\\nmodels like GPT-4o and Claude-3.5-Sonnet.\\n31')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb.similarity_search(query=\"how many parameters in deep-seek v3?\",k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cff7634",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
